{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaeSaeeda/ComputerScience-2022-2025/blob/main/language_technology_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vbQSYb1HVHvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe72be68-46e0-42b8-d04a-59cad9aa5535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "#nessasary imports for the project\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "!pip install pandas requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1JjMy1dXqq7",
        "outputId": "7277f5d6-b5ca-4331-9a52-b3a8a2ab8c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kdramas information saved to 'kdramas_info.csv'\n"
          ]
        }
      ],
      "source": [
        "#creates the primary table for the project, going through each link and adding it to the series column\n",
        "url = \"https://en.wikipedia.org/wiki/Korean_drama\"\n",
        "response = requests.get(url)\n",
        "#checks if information can be scraped from the website\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    table = soup.find_all('table', {'class': 'wikitable'})[2]\n",
        "\n",
        "    if table:\n",
        "        df = pd.read_html(str(table), header=0)[0]\n",
        "        df['Network'].fillna(method='ffill', inplace=True)\n",
        "        df = df.drop(columns=['Ref'])\n",
        "        df.to_csv('kdramas_info.csv', index=False, encoding='utf-8')\n",
        "\n",
        "        print(\"Kdramas information saved to 'kdramas_info.csv'\")\n",
        "    else:\n",
        "        print(\"Table not found on the page.\")\n",
        "else:\n",
        "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siBczvTP7m52",
        "outputId": "25bbc7aa-141b-4a5c-dbec-c0f7313eb316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kdramas information saved to 'kdramas_info.csv'\n"
          ]
        }
      ],
      "source": [
        "#adding the column called drama link which is the hyperlink of the drama\n",
        "url = \"https://en.wikipedia.org/wiki/Korean_drama\"\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    table = soup.find_all('table', {'class': 'wikitable'})[2]\n",
        "    if table:\n",
        "        df = pd.read_html(str(table), header=0)[0]\n",
        "        df['Network'].fillna(method='ffill', inplace=True)\n",
        "        drama_links = []\n",
        "        for cell in table.select('tr td:nth-of-type(2)'):\n",
        "            link = cell.find('a')\n",
        "            drama_links.append(link['href'] if link else None)\n",
        "        df['Drama Link'] = drama_links\n",
        "        df = df.drop(columns=['Ref'])\n",
        "\n",
        "        df.to_csv('kdramas_info.csv', index=False, encoding='utf-8')\n",
        "\n",
        "        print(\"Kdramas information saved to 'kdramas_info.csv'\")\n",
        "    else:\n",
        "        print(\"Table not found on the page.\")\n",
        "else:\n",
        "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k23cEftrYyPv",
        "outputId": "12281edf-6ff4-4ea5-fcb4-d6013633bad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kdramas information with cast details saved to 'kdramas_info_with_cast.csv'\n"
          ]
        }
      ],
      "source": [
        "#gets the cast members of the kdrama,\n",
        "def get_cast_info(series_url):\n",
        "    response = requests.get(series_url)\n",
        "    if response.status_code == 200:\n",
        "        series_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        cast_heading = series_soup.find('span', {'id': 'Cast'})\n",
        "        cast_text = ''\n",
        "\n",
        "        if cast_heading:\n",
        "            parent_section = cast_heading.find_parent()\n",
        "            paragraphs = []\n",
        "            current_element = parent_section.find_next()\n",
        "\n",
        "            while current_element and not current_element.name.startswith('h2'):\n",
        "                if current_element.name in ['p', 'ul', 'ol', 'dl']:\n",
        "                    paragraphs.append(current_element.get_text(strip=True))\n",
        "                current_element = current_element.find_next()\n",
        "            cast_text = '\\n'.join(paragraphs)\n",
        "\n",
        "        return cast_text.strip()\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to retrieve the series page. Status code: {response.status_code}\")\n",
        "        return None\n",
        "df = pd.read_csv('kdramas_info.csv')\n",
        "df['Series Link'] = df.apply(lambda row: f\"https://en.wikipedia.org{row['Drama Link']}\" if pd.notnull(row['Drama Link']) and row['Drama Link'].startswith('/wiki/') else None, axis=1)\n",
        "df['Cast'] = ''\n",
        "for index, row in df.iterrows():\n",
        "    series_url = row['Series Link']\n",
        "    if pd.notnull(series_url):\n",
        "        cast_info = get_cast_info(series_url)\n",
        "        if cast_info is not None:\n",
        "            df.at[index, 'Cast'] = cast_info if cast_info else 'N/A'\n",
        "df.to_csv('kdramas_info_with_cast.csv', index=False, encoding='utf-8')\n",
        "print(\"Kdramas information with cast details saved to 'kdramas_info_with_cast.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fy2rC8U_zZq",
        "outputId": "377d4892-e4ed-4033-c12a-9b3a227863f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kdramas cast and synopsis information saved to 'kdramas_info_with_cast_and_synopsis.csv'\n"
          ]
        }
      ],
      "source": [
        "#adds the synopsis and plot to the culumn and adds it to the casts csv\n",
        "def get_synopsis_info(series_url):\n",
        "    response = requests.get(series_url)\n",
        "    if response.status_code == 200:\n",
        "        series_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        synopsis_heading = series_soup.find('span', {'id': 'Synopsis'})\n",
        "        plot_heading = series_soup.find('span', {'id': 'Plot'})\n",
        "\n",
        "        if synopsis_heading:\n",
        "            parent_section = synopsis_heading.find_parent()\n",
        "        elif plot_heading:\n",
        "            parent_section = plot_heading.find_parent()\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "        next_h2 = parent_section.find_next('h2')\n",
        "        paragraphs = parent_section.find_all_next(['p', 'ul', 'ol', 'dl', 'h2'])\n",
        "        paragraphs = paragraphs[:paragraphs.index(next_h2)] if next_h2 else paragraphs\n",
        "\n",
        "        synopsis_text = '\\n'.join(paragraph.get_text(strip=True) for paragraph in paragraphs)\n",
        "        return synopsis_text.strip()\n",
        "\n",
        "    print(f\"Failed to retrieve the series page. Status code: {response.status_code}\")\n",
        "    return None\n",
        "\n",
        "df = pd.read_csv('kdramas_info_with_cast.csv')\n",
        "df['Synopsis'] = ''\n",
        "for index, row in df.iterrows():\n",
        "    series_url = row['Series Link']\n",
        "    if pd.notnull(series_url):\n",
        "        synopsis_info = get_synopsis_info(series_url)\n",
        "        if synopsis_info is not None:\n",
        "            df.at[index, 'Synopsis'] = synopsis_info if synopsis_info else 'N/A'\n",
        "\n",
        "df.to_csv('kdramas_info_with_cast_and_synopsis.csv', index=False, encoding='utf-8')\n",
        "print(\"Kdramas cast and synopsis information saved to 'kdramas_info_with_cast_and_synopsis.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# table is created to show the available information\n",
        "\n",
        "df = pd.read_csv('/content/kdramas_info_with_cast_and_synopsis.csv')\n",
        "\n",
        "# Display information about series, cast, and synopsis\n",
        "table_data = []\n",
        "for index, row in df.iterrows():\n",
        "    series_name = row['Series']\n",
        "    cast_info = 'Contains data' if pd.notna(row['Cast']) else 'No data collected'\n",
        "    synopsis_info = 'Contains data' if pd.notna(row['Synopsis']) else 'No data collected'\n",
        "    table_data.append([series_name, cast_info, synopsis_info])\n",
        "\n",
        "headers = ['Series', 'Cast', 'Synopsis']\n",
        "table = tabulate(table_data, headers=headers, tablefmt='grid')\n",
        "\n",
        "print(\"\\nK-Dramas Information Table:\")\n",
        "print(table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X35vvMBkrBia",
        "outputId": "374af49e-77df-4b88-c7d5-fbfbf547d2d6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "K-Dramas Information Table:\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Series                             | Cast          | Synopsis      |\n",
            "+====================================+===============+===============+\n",
            "| The World of the Married           | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Reborn Rich                        | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Sky Castle                         | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Crash Landing on You               | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Reply 1988                         | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Guardian: The Lonely and Great God | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Doctor Cha                         | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Mr. Sunshine                       | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Extraordinary Attorney Woo         | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Mr. Queen                          | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Crash Course in Romance            | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Under the Queen's Umbrella         | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Love (ft. Marriage and Divorce) 2  | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Itaewon Class                      | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Agency                             | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Vincenzo                           | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Our Blues                          | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| 100 Days My Prince                 | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Hospital Playlist                  | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Hospital Playlist 2                | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| King the Land                      | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Hometown Cha-Cha-Cha               | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Signal                             | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| The Lady in Dignity                | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| The Good Bad Mother                | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Hotel del Luna                     | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Red Balloon                        | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Twenty-Five Twenty-One             | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Reply 1994                         | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Prison Playbook                    | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Little Women                       | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| The Uncanny Counter                | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| The Crowned Clown                  | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| My Kids Give Me a Headache         | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Jirisan                            | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Mine                               | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Strong Girl Nam-soon               | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Love (ft. Marriage and Divorce) 3  | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Show Window: The Queen's House     | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Encounter                          | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Military Prosecutor Doberman       | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Memories of the Alhambra           | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Another Miss Oh                    | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Bossam: Steal the Fate             | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| The Light in Your Eyes             | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Strong Girl Bong-soon              | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Love (ft. Marriage and Divorce)    | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Alchemy of Souls: Light and Shadow | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Behind Your Touch                  | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n",
            "| Divorce Attorney Shin              | Contains data | Contains data |\n",
            "+------------------------------------+---------------+---------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8b5UlqRjTKM",
        "outputId": "427cee0c-86a8-4fab-c82b-86505d972c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Useful and necessary imports\n",
        "!pip install pandas transformers\n",
        "import pandas as pd\n",
        "from transformers import pipeline, BertTokenizerFast, BartForConditionalGeneration\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from transformers import pipeline, BertTokenizerFast, BartTokenizerFast\n",
        "\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import time\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize NLP models\n",
        "qa_model = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
        "nlp_bert = pipeline('question-answering', model=qa_model, tokenizer=BertTokenizerFast.from_pretrained('bert-base-uncased'))\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/kdramas_info_with_cast_and_synopsis.csv')\n",
        "\n",
        "# Summarization model\n",
        "summarization_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "from transformers import BartTokenizerFast\n",
        "\n",
        "def summarize_text(text, max_length=50):\n",
        "    tokenizer = BartTokenizerFast.from_pretrained('facebook/bart-large-cnn')\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    summary_ids = summarization_model.generate(\n",
        "        inputs['input_ids'],\n",
        "        max_length=max_length,\n",
        "        min_length=40,\n",
        "        length_penalty=2.0,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "tokenizer = BartTokenizerFast.from_pretrained('facebook/bart-large-cnn')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG7q-8iYW6LE",
        "outputId": "1a0de7c8-8139-429e-e183-cc0ee645a31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“º Welcome to the Fun K-Drama Guessing Game! ğŸŒŸ\n",
            "Think of a K-drama, and I'll try to guess it. Let's get started!\n",
            "\n",
            "ğŸ” Provide a question ('question'), remember the actor ('actor'), or title ('title'), or type 'quit' to exit: title\n",
            "\n",
            "ğŸ“– Enter the K-drama title: uncanny\n",
            "\n",
            "ğŸŒŸ Best Guess: The Uncanny Counter\n",
            "ğŸ“„ Summary: In the fictional city of Jungjin, a group of four demon-hunters called theCountersbear the arduous task of searching for andbanishingevil spirits. The Counters were once incomaswhen a partner spirit from Yung, the boundary between the afterlife and the world of the living,possessesthem and gives them perfectly healthy bodies and consciousness.\n",
            "\n",
            "ğŸ¤– Chatbot: Is it 'The Uncanny Counter'? (Type 'yay' for yes, 'nay' for no, or 'ask' for more): yay\n",
            "\n",
            "ğŸ‰ Chatbot: Yay! You're a K-Drama genius! Thanks for playing! ğŸŠ\n",
            "\n",
            "ğŸŒŸ Your Total Title Score: 10\n",
            "ğŸŒŸ Your Total Actor Score: 0\n",
            "ğŸŒŸ Your Total Question Score: 0\n",
            "\n",
            "ğŸ” Provide a question ('question'), remember the actor ('actor'), or title ('title'), or type 'quit' to exit: actor\n",
            "\n",
            "ğŸ•µï¸ Enter the actor's name: kim\n",
            "\n",
            "ğŸŒŸ Best Guess: The World of the Married\n",
            "\n",
            "ğŸ¤– Chatbot: Was my guess correct? (Type 'yay' for yes or 'nay' for no): yay\n",
            "\n",
            "ğŸ˜„ Chatbot: Yay! You earned 10 points!\n",
            "\n",
            "ğŸ” Provide a question ('question'), remember the actor ('actor'), or title ('title'), or type 'quit' to exit: actor\n",
            "\n",
            "ğŸ•µï¸ Enter the actor's name: hyun bin\n",
            "\n",
            "ğŸŒŸ Best Guess: Crash Landing on You\n",
            "\n",
            "ğŸ¤– Chatbot: Was my guess correct? (Type 'yay' for yes or 'nay' for no): yay\n",
            "\n",
            "ğŸ˜„ Chatbot: Yay! You earned 10 points!\n",
            "\n",
            "ğŸ” Provide a question ('question'), remember the actor ('actor'), or title ('title'), or type 'quit' to exit: question\n",
            "\n",
            "â“ What specific question would you like to ask about the drama? it is about a woman who ends up in north korea\n",
            "\n",
            "ğŸ¤– Chatbot: Let me think about that...\n",
            "\n",
            "âŒ Unable to find a relevant Kdrama based on the provided question.\n",
            "\n",
            "ğŸ¤– Chatbot: No worries! Let's keep the fun going!\n",
            "ğŸ¤– By my Language processing model, this is what you are looking for: {'score': 0.02093411609530449, 'start': 6410, 'end': 6421, 'answer': 'North Korea'}\n",
            "\n",
            "ğŸ” Provide a question ('question'), remember the actor ('actor'), or title ('title'), or type 'quit' to exit: quir\n",
            "\n",
            "â— Chatbot: Please type 'question', 'title', 'actor', or 'quit'.\n",
            "\n",
            "ğŸ” Provide a question ('question'), remember the actor ('actor'), or title ('title'), or type 'quit' to exit: quit\n",
            "\n",
            "ğŸ¤– Chatbot: Thanks for playing! See you next time! ğŸŒŸ\n",
            "\n",
            "ğŸ¤– Chatbot: Thanks for playing! Here's a K-Drama joke for you:\n",
            "Why did the K-Drama break up with reality TV? It needed more plot twists!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Initialize scores and excluded dramas list\n",
        "title_score = 0\n",
        "actor_score = 0\n",
        "question_score = 0\n",
        "excluded_dramas = []\n",
        "\n",
        "# Welcome message\n",
        "print(\"\\nğŸ“º Welcome to the Fun K-Drama Guessing Game! ğŸŒŸ\")\n",
        "print(\"Think of a K-drama, and I'll try to guess it. Let's get started!\")\n",
        "\n",
        "# Main game loop\n",
        "while True:\n",
        "    # User input for action\n",
        "    user_input = input(\"\\nğŸ” Provide a question ('question'), remember the actor ('actor'), or title ('title'), or type 'quit' to exit: \").lower()\n",
        "\n",
        "    # Exit the game\n",
        "    if user_input == 'quit':\n",
        "        print(\"\\nğŸ¤– Chatbot: Thanks for playing! See you next time! ğŸŒŸ\")\n",
        "        break\n",
        "\n",
        "    # Question-based guess\n",
        "    if user_input == 'question':\n",
        "        user_question = input(\"\\nâ“ What specific question would you like to ask about the drama? \")\n",
        "        print(\"\\nğŸ¤– Chatbot: Let me think about that...\")\n",
        "        time.sleep(2)\n",
        "        result = nlp_bert(question=user_question, context=df['Synopsis'].str.cat(sep='\\n'))\n",
        "\n",
        "        if 'index' in result:\n",
        "            relevant_kdrama_details = df.iloc[result['index']]\n",
        "            series_name = relevant_kdrama_details['Series']\n",
        "            print(f\"\\nğŸ­ Title: {series_name}\")\n",
        "            print(f\"ğŸ“ Answer: {result['answer']}\")\n",
        "            response = input(\"\\nğŸ¤– Chatbot: Was my guess correct? (Type 'yay' for yes or 'nay' for no): \").lower()\n",
        "\n",
        "            if response == 'yay':\n",
        "                print(\"\\nğŸ˜„ Chatbot: Yay! You earned 10 points!\")\n",
        "                question_score += 10\n",
        "            elif response == 'nay':\n",
        "                print(\"\\nğŸ¤” Chatbot: Oops! Let's keep the fun going!\")\n",
        "            else:\n",
        "                print(\"\\nâ— Chatbot: Please type 'yay' for yes or 'nay' for no.\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\nâŒ Unable to find a relevant Kdrama based on the provided question.\")\n",
        "            print(\"\\nğŸ¤– Chatbot: No worries! Let's keep the fun going!\")\n",
        "            print(\"ğŸ¤– By my Language processing model, this is what you are looking for:\", result)\n",
        "\n",
        "    # Title-based guess\n",
        "    elif user_input == 'title':\n",
        "        user_input_title = input(\"\\nğŸ“– Enter the K-drama title: \")\n",
        "        matching_rows_title = df[df['Series'].str.lower().fillna('').str.contains(user_input_title.lower())]\n",
        "\n",
        "        if not matching_rows_title.empty:\n",
        "            best_drama_title = matching_rows_title.iloc[0]['Series']\n",
        "            print(f\"\\nğŸŒŸ Best Guess: {best_drama_title}\")\n",
        "            # Use summarization model for the synopsis\n",
        "            summarized_synopsis = summarize_text(matching_rows_title.iloc[0]['Synopsis'])\n",
        "            print(f\"ğŸ“„ Summary: {summarized_synopsis}\")\n",
        "            title_score += 10\n",
        "        else:\n",
        "            print(f\"\\nğŸ¤” Chatbot: Couldn't find information for the K-drama '{user_input_title}'. Please try again.\")\n",
        "            print(\"\\nğŸ˜… Chatbot: No worries! Let's keep the excitement alive!\")\n",
        "            continue\n",
        "\n",
        "        response = input(f\"\\nğŸ¤– Chatbot: Is it '{best_drama_title}'? (Type 'yay' for yes, 'nay' for no, or 'ask' for more): \").lower()\n",
        "\n",
        "        if response == 'yay':\n",
        "            print(\"\\nğŸ‰ Chatbot: Yay! You're a K-Drama genius! Thanks for playing! ğŸŠ\")\n",
        "            print(f\"\\nğŸŒŸ Your Total Title Score: {title_score}\")\n",
        "            print(f\"ğŸŒŸ Your Total Actor Score: {actor_score}\")\n",
        "            print(f\"ğŸŒŸ Your Total Question Score: {question_score}\")\n",
        "        elif response == 'nay':\n",
        "            print(f\"\\nğŸ¤” Chatbot: Okay, let's try another word. Excluding '{best_drama_title}' for now.\")\n",
        "            excluded_dramas.append(best_drama_title)\n",
        "        elif response == 'ask':\n",
        "            questions = [input(\"\\nâ“ What specific question would you like to ask about the drama? \")]\n",
        "\n",
        "            with ThreadPoolExecutor() as executor:\n",
        "                results = list(executor.map(lambda q: nlp_bert(question=q, context=df['Synopsis'].str.cat(sep='\\n')), questions))\n",
        "\n",
        "            for result in results:\n",
        "                if 'index' in result:\n",
        "                    relevant_kdrama_details = df.iloc[result['index']]\n",
        "                    print(f\"\\nğŸ­ Title: {relevant_kdrama_details['Series']}\")\n",
        "                    print(f\"ğŸ“ Answer: {result['answer']}\")\n",
        "                    print(\"\\nğŸ˜„ Chatbot: Great question! You earned 10 points!\")\n",
        "                    question_score += 10\n",
        "                else:\n",
        "                    print(\"\\nâŒ Unable to find a relevant Kdrama based on the provided question.\")\n",
        "                    print(\"\\nğŸ˜… Chatbot: No problem! Let's continue the fun journey!\")\n",
        "\n",
        "            print(\"ğŸ¤– By my Language processing model, this is what you are looking for:\", result)\n",
        "        else:\n",
        "            print(\"\\nâ— Chatbot: Please type 'yay' for yes, 'nay' for no, 'ask' for more, or 'quit' to exit.\")\n",
        "\n",
        "    # Actor-based guess\n",
        "    elif user_input == 'actor':\n",
        "        user_input_actor = input(\"\\nğŸ•µï¸ Enter the actor's name: \")\n",
        "        matching_rows_actor = df[df['Cast'].str.lower().fillna('').str.contains(user_input_actor.lower())]\n",
        "\n",
        "        if not matching_rows_actor.empty:\n",
        "            best_drama_actor = matching_rows_actor.iloc[0]['Series']\n",
        "            print(f\"\\nğŸŒŸ Best Guess: {best_drama_actor}\")\n",
        "            response_actor = input(\"\\nğŸ¤– Chatbot: Was my guess correct? (Type 'yay' for yes or 'nay' for no): \").lower()\n",
        "\n",
        "            if response_actor == 'yay':\n",
        "                print(\"\\nğŸ˜„ Chatbot: Yay! You earned 10 points!\")\n",
        "                actor_score += 10\n",
        "            elif response_actor == 'nay':\n",
        "                print(\"\\nğŸ¤” Chatbot: Oops! Let's keep the fun going!\")\n",
        "            else:\n",
        "                print(\"\\nâ— Chatbot: Please type 'yay' for yes or 'nay' for no.\")\n",
        "\n",
        "        else:\n",
        "            print(f\"\\nğŸ¤” Chatbot: Couldn't find a K-drama for the actor '{user_input_actor}'. Please try again.\")\n",
        "            print(\"\\nğŸ˜… Chatbot: Don't worry! Let's keep the fun rolling!\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\nâ— Chatbot: Please type 'question', 'title', 'actor', or 'quit'.\")\n",
        "\n",
        "# Display a closing K-Drama joke\n",
        "jokes = [\n",
        "    \"Why did the K-Drama cross the road? To reach the next season!\",\n",
        "    \"What do you call a K-Drama that makes you laugh and cry? A masterPIECE!\",\n",
        "    \"Why did the K-Drama break up with reality TV? It needed more plot twists!\"\n",
        "]\n",
        "print(f\"\\nğŸ¤– Chatbot: Thanks for playing! Here's a K-Drama joke for you:\\n{random.choice(jokes)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Load your kdramas dataset\n",
        "df = pd.read_csv('/content/kdramas_info_with_cast_and_synopsis.csv')\n",
        "excluded_dramas = {}\n",
        "cumulative_scores = {}\n",
        "\n",
        "# Load spaCy model for named entity recognition\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize scores\n",
        "title_score = 0\n",
        "actor_score = 0\n",
        "question_score = 0\n",
        "\n",
        "# Welcome message\n",
        "print(\"\\nğŸ“º Welcome to the Fun K-Drama Guessing Game! ğŸŒŸ\")\n",
        "print(\"Think of a K-drama, and I'll try to guess it. Let's get started!\")\n",
        "\n",
        "# Main game loop\n",
        "while True:\n",
        "    # User input for action\n",
        "    user_input = input(\"\\nğŸ” Provide a keyword ('keyword'), remember the actor ('actor'), title ('title'), or type 'quit' to exit: \").lower()\n",
        "\n",
        "    # Exit the game\n",
        "    if user_input == 'quit':\n",
        "        print(\"\\nğŸ¤– Chatbot: Thanks for playing! See you next time! ğŸŒŸ\")\n",
        "        break\n",
        "\n",
        "    # Question-based guess\n",
        "    if user_input == 'keyword':\n",
        "        user_question = input(\"\\nâ“ What specific kwywords come to mindnay? \")\n",
        "        print(\"\\nğŸ¤– Chatbot: Let me think about that...\")\n",
        "\n",
        "        # Use spaCy for named entity recognition\n",
        "        doc = nlp(user_question)\n",
        "        cast_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
        "\n",
        "        df['combined_info'] = df['Series'] + ' ' + df['Synopsis'] + ' ' + df['Cast']\n",
        "\n",
        "        matching_rows = df[~df['Series'].isin(excluded_dramas.keys())].copy()\n",
        "\n",
        "        if not matching_rows.empty:\n",
        "            matching_rows['score'] = matching_rows.apply(\n",
        "                lambda x: sum(\n",
        "                    (10 if word.lower() in str(x['Series']).lower() else 1) +\n",
        "                    (5 if word.lower() in str(x['Synopsis']).lower() else 1) +\n",
        "                    (2 if any(cast.lower() in str(x['Cast']).lower() for cast in cast_names) else 1)\n",
        "                    for word in user_question.split()\n",
        "                )\n",
        "                if pd.notna(x['Series']) else 0,\n",
        "                axis=1\n",
        "            )\n",
        "            for idx, row in matching_rows.iterrows():\n",
        "                series = row['Series']\n",
        "                score = row['score']\n",
        "                cumulative_scores[series] = cumulative_scores.get(series, 0) + score\n",
        "            best_drama, highest_score = max(cumulative_scores.items(), key=lambda x: x[1])\n",
        "            print(f\"\\nBest Guess: {best_drama} with a cumulative score of {highest_score}\")\n",
        "\n",
        "            relevant_info = matching_rows.loc[matching_rows['score'].idxmax()]\n",
        "            title = relevant_info['Series']\n",
        "            response = input(f\"\\nChatbot: Is it '{title}'? (Type 'yay' for yes, 'nay' for no, or 'ask' for more): \").lower()\n",
        "\n",
        "            if response == 'yay':\n",
        "                print(\"\\nğŸ˜„ Chatbot: Yay! You're correct!\")\n",
        "                question_score += 10\n",
        "                print(f\"\\nğŸŒŸ Your Total Title Score: {title_score}\")\n",
        "                print(f\"ğŸŒŸ Your Total Actor Score: {actor_score}\")\n",
        "                print(f\"ğŸŒŸ Your Total Question Score: {question_score}\")\n",
        "            elif response == 'nay':\n",
        "                print(f\"\\nChatbot: Okay, let's try another word. Excluding '{title}' for now.\")\n",
        "                excluded_dramas[title] = True\n",
        "            elif response == 'ask':\n",
        "                # Ask a question to narrow down the possibilities using a simple keyword search\n",
        "                user_question = input(\"\\nChatbot: What specific question would you like to ask about the drama? \")\n",
        "                relevant_rows = df[df['Synopsis'].str.contains(user_question, case=False)]\n",
        "\n",
        "                if not relevant_rows.empty:\n",
        "                    print(\"\\nChatbot: Here are some dramas that match your question:\")\n",
        "                    print(relevant_rows[['Series', 'Synopsis']])\n",
        "                else:\n",
        "                    print(\"Chatbot: I couldn't find relevant information based on your question.\")\n",
        "            else:\n",
        "                print(\"\\nChatbot: Please type 'yay' for yes, 'nay' for no, or 'ask' for more.\")\n",
        "        else:\n",
        "            print(\"\\nChatbot: I'm sorry, I couldn't find relevant information based on your input.\")\n",
        "\n",
        "    # Title-based guess\n",
        "    elif user_input == 'title':\n",
        "        user_input_title = input(\"\\nğŸ“– Enter the K-drama title: \")\n",
        "        matching_rows_title = df[df['Series'].str.lower().fillna('').str.contains(user_input_title.lower())]\n",
        "\n",
        "        if not matching_rows_title.empty:\n",
        "            best_drama_title = matching_rows_title.iloc[0]['Series']\n",
        "            print(f\"\\nğŸŒŸ Best Guess: {best_drama_title}\")\n",
        "            # Use summarization model for the synopsis\n",
        "            summarized_synopsis = summarize_text(matching_rows_title.iloc[0]['Synopsis'])\n",
        "            print(f\"ğŸ“„ Summary: {summarized_synopsis}\")\n",
        "            title_score += 10\n",
        "        else:\n",
        "            print(f\"\\nğŸ¤” Chatbot: Couldn't find information for the K-drama '{user_input_title}'. Please try again.\")\n",
        "            print(\"\\nğŸ˜… Chatbot: No worries! Let's keep the excitement alive!\")\n",
        "            continue\n",
        "\n",
        "        response = input(f\"\\nğŸ¤– Chatbot: Is it '{best_drama_title}'? (Type 'yay' for yes, 'nay' for no, or 'ask' for more): \").lower()\n",
        "\n",
        "        if response == 'yay':\n",
        "            print(\"\\nğŸ‰ Chatbot: Yay! You're a K-Drama genius!\")\n",
        "            title_score += 10\n",
        "            print(f\"\\nğŸŒŸ Your Total Title Score: {title_score}\")\n",
        "            print(f\"ğŸŒŸ Your Total Actor Score: {actor_score}\")\n",
        "            print(f\"ğŸŒŸ Your Total Question Score: {question_score}\")\n",
        "        elif response == 'nay':\n",
        "            print(f\"\\nChatbot: Okay, let's try another word. Excluding '{best_drama_title}' for now.\")\n",
        "            excluded_dramas[best_drama_title] = True\n",
        "        elif response == 'ask':\n",
        "            questions = [input(\"\\nâ“ What specific question would you like to ask about the drama? \")]\n",
        "\n",
        "            with ThreadPoolExecutor() as executor:\n",
        "                results = list(executor.map(lambda q: nlp_bert(question=q, context=df['Synopsis'].str.cat(sep='\\n')), questions))\n",
        "\n",
        "            for result in results:\n",
        "                if 'index' in result:\n",
        "                    relevant_kdrama_details = df.iloc[result['index']]\n",
        "                    print(f\"\\nğŸ­ Title: {relevant_kdrama_details['Series']}\")\n",
        "                    print(f\"ğŸ“ Answer: {result['answer']}\")\n",
        "                    print(\"\\nğŸ˜„ Chatbot: Great question! You earned 10 points!\")\n",
        "                    question_score += 10\n",
        "                else:\n",
        "                    print(\"\\nâŒ Unable to find a relevant Kdrama based on the provided question.\")\n",
        "                    print(\"\\nğŸ˜… Chatbot: No problem! Let's continue the fun journey!\")\n",
        "\n",
        "                print(\"ğŸ¤– By my Language processing model, this is what you are looking for:\", result)\n",
        "        else:\n",
        "            print(\"\\nâ— Chatbot: Please type 'yay' for yes, 'nay' for no, 'ask' for more, or 'quit' to exit.\")\n",
        "\n",
        "    # Actor-based guess\n",
        "    elif user_input == 'actor':\n",
        "        user_input_actor = input(\"\\nğŸ•µï¸ Enter the actor's name: \")\n",
        "        matching_rows_actor = df[df['Cast'].str.lower().fillna('').str.contains(user_input_actor.lower())]\n",
        "\n",
        "        if not matching_rows_actor.empty:\n",
        "            best_drama_actor = matching_rows_actor.iloc[0]['Series']\n",
        "            print(f\"\\nğŸŒŸ Best Guess: {best_drama_actor}\")\n",
        "            response_actor = input(\"\\nğŸ¤– Chatbot: Was my guess correct? (Type 'yay' for yes or 'nay' for no): \").lower()\n",
        "\n",
        "            if response_actor == 'yay':\n",
        "                print(\"\\nğŸ˜„ Chatbot: Yay! You earned 10 points!\")\n",
        "                actor_score += 10\n",
        "            elif response_actor == 'nay':\n",
        "                print(\"\\nğŸ¤” Chatbot: Oops! Let's keep the fun going!\")\n",
        "            else:\n",
        "                print(\"\\nâ— Chatbot: Please type 'yay' for yes or 'nay' for no.\")\n",
        "\n",
        "        else:\n",
        "            print(f\"\\nğŸ¤” Chatbot: Couldn't find a K-drama for the actor '{user_input_actor}'. Please try again.\")\n",
        "            print(\"\\nğŸ˜… Chatbot: Don't worry! Let's keep the fun rolling!\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\nâ— Chatbot: Please type 'question', 'title', 'actor', or 'quit'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "UEdacN9VOo2P",
        "outputId": "66387af1-6f0a-4d7d-a50b-bef4f83f405d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“º Welcome to the Fun K-Drama Guessing Game! ğŸŒŸ\n",
            "Think of a K-drama, and I'll try to guess it. Let's get started!\n",
            "\n",
            "ğŸ” Provide a keyword ('keyword'), remember the actor ('actor'), title ('title'), or type 'quit' to exit: keyword\n",
            "\n",
            "â“ What specific kwywords come to mind? jeju \n",
            "\n",
            "ğŸ¤– Chatbot: Let me think about that...\n",
            "\n",
            "Best Guess: Our Blues with a cumulative score of 7\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8a8f12e7de79>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mrelevant_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatching_rows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatching_rows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelevant_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Series'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nChatbot: Is it '{title}'? (Type 'yay' for yes, 'nay' for no, or 'ask' for more): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'yay'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6u0yp9kZbENAGDL3rT8gw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}